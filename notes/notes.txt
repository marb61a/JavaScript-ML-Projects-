Conversational AI + NLP
    - Python has a lot of AI libraries
    - JavaScript has libraries which will help avoid having to work through Python\API

NLP - Natural Language Processing
    - This is the study of the interactions between computers and human languages
    - It is a huge area and constantly evolving
    - It is not just a sub area of AI but also Computation and Linguistics

NLU - Natural Language Understanding
    - A group of techniques to convert non-structured inputs in natural language in structured inputs that can be managed by a computer
        - For example different languages have different ways of constructing sentences, some put the verb before the subject others the opposite approach
    - One application is classification
        - This is the most important part of a chatbot

NLG - Natural Language Generator
    - This converts computer output into natural language
        - This will include gender, plurals, context etc
        - For example User has 1 new message and User has 2 new messages

NER - Named Entity Recognition
    - This extracts entities from natural language sentences
        - It will recognise numbers, dates, emails, hashtags etc
        - Numbers when declared numerically are the same in multiple languages eg 500
        - This changes when the number is stated using alphabetical characters eg five hundred
        - This means different extraction methods for different languages for dates, numbers, currencties etc

Utterance
    - This is a sentence in a natural language
    - Usually utterances can be thought of as the sentences used to train a bot or by users

Intent
    - This is each of the different things that a chatbot knows how to answer
    - When an utterance is received NLU classifies the utterance into intents

Entity
    - If intents are the various actions that a chatbot can execute
        - then entities are the parameters that can be extracted from the utterances to provide arguments for actions
    - For example if a chatbot can understand the intent "eat" and a person say "I want to eat pizza" then pizza is an entity
    - Intents can be thought of as functions and entities as their parameters

Corpus
    - This is the file or other media with the training information for the NUL\bot
    - It will contain the intents and for each intent the utterances
    - It will also contain the language, name of the corpus, validation utterances and answers
        - Answers are for a Q&A corpus
    - The plural is Corpora

Channel
    - A channel is where a chatbot can be deployed
    - There are multiple places WhatsApp, Mobile, Web, API, Alexa, MS Teams and Facebook Messanger to name a few
    - There should be only one backend which connects to multiple channels

JS libraries
    - Brain.js
        - GPU accelerated Neural networks in JavaScript for Browsers and Node.js 
        - https://brain.js.org/#/
    - Tensorflow.js
        - A library for machine learning in JavaScript 
        - https://www.tensorflow.org/js
        - npm install @tensorflow/tfjs-node (When installing on node!!)
    - These may be similar but Tensorflow is probably more complete
        - Also Tensorflow is asynchronous where as Brain.js is not
        - There may also be a need to rebuild bindings if environmental variables are changed

Regressions
    - Using both brain.js and Tensorflow.js for an Abelone example
    - This will be calculating the age of the Abelone from the rings

AI - Artificial Intelligence
    - Machine Learning and Deep Learning are part of AI
    - Deep Learning is a subset of Machine Learning

Classifiers
    - There are multiple classifiers, again a Brain.js and Tensorflow.js version will be done
    - Classification will include normalization and tokenisation
    - Text classification is the process of assigning tags or categories to text according to its content
        - It is a fundamental tasks of NLP and has broad applications
        - These include sentiment analysis, topic labeling, spam detection, and intent detection
    - Text classification can be done two different ways: manual or automatic classification
        - The latter is where NLP, AI and Machine Learning come in
    - There are many approaches to automatic NLP text classification, which fall into into three types of systems:
        - Rule-Based Systems
            - Rule-based approaches classify text into organized groups by using a set of handcrafted linguistic rules
            - These rules instruct the system to use semantically relevant elements of a text to identify relevant categories based on its content
            - Each rule consists of an antecedent or pattern and a predicted category
            - Rule-based systems are human comprehensible and can be improved over time
            - There are disadvantages to using this approach
                - There is specific in-depth domain knowledge needed
                - There is usually a lot of testing and analysis needed which makes this approach very time consuming
                - This approach is also difficult to maintain and may not scale well
        - Machine learning-based systems
            - Machine learning text classification learns to make classifications based on past observations
            - By using pre-labeled examples as training data, machine learning algorithms can learn the different associations between pieces of text
            - A “tag” is the pre-determined classification or category that any given text could fall into
            - The first step in training a machine learning NLP classifier is feature extraction which is a method to transform text into numerical values
                - This representation is in the form of a vector
                - One of the most frequently used approaches is bag of words, where a vector represents the frequency of a word in a predefined dictionary of words
            - There are multiple machine learning algorithms for creating text classification models
                - These include the Naive Bayes family of algorithms, support vector machines (SVM), and deep learning
        - Hybrid Systems
            - Hybrid systems combine a machine learning-trained base classifier with a rule-based system, used to further improve the results
            - These can be easily fine-tuned by adding specific rules for those conflicting tags that haven’t been correctly modeled by the base classifier

!! Normalization
    - https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/normalize

!! Natural
    - This package is a general natural language facility for nodejs
        - https://github.com/NaturalNode/natural
    - npm install natural
    - There are several tokenisers available in this package

!!! When writing in a foreign language there may be special character which even native speakers may forget to add
    - For example there are a couple of above vowel characters in French called accents, in Spanish too and others
    - These change both the sound and in some case meaning of words so is important to remember
