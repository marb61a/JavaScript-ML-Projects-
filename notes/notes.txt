Conversational AI + NLP
    - Python has a lot of AI libraries
    - JavaScript has libraries which will help avoid having to work through Python\API

NLP - Natural Language Processing
    - This is the study of the interactions between computers and human languages
    - It is a huge area and constantly evolving
    - It is not just a sub area of AI but also Computation and Linguistics

NLU - Natural Language Understanding
    - A group of techniques to convert non-structured inputs in natural language in structured inputs that can be managed by a computer
        - For example different languages have different ways of constructing sentences, some put the verb before the subject others the opposite approach
    - One application is classification
        - This is the most important part of a chatbot

NLG - Natural Language Generator
    - This converts computer output into natural language
        - This will include gender, plurals, context etc
        - For example User has 1 new message and User has 2 new messages

NER - Named Entity Recognition
    - This extracts entities from natural language sentences
        - It will recognise numbers, dates, emails, hashtags etc
        - Numbers when declared numerically are the same in multiple languages eg 500
        - This changes when the number is stated using alphabetical characters eg five hundred
        - This means different extraction methods for different languages for dates, numbers, currencties etc

Utterance
    - This is a sentence in a natural language
    - Usually utterances can be thought of as the sentences used to train a bot or by users

Intent
    - This is each of the different things that a chatbot knows how to answer
    - When an utterance is received NLU classifies the utterance into intents

Entity
    - If intents are the various actions that a chatbot can execute
        - then entities are the parameters that can be extracted from the utterances to provide arguments for actions
    - For example if a chatbot can understand the intent "eat" and a person say "I want to eat pizza" then pizza is an entity
    - Intents can be thought of as functions and entities as their parameters

Corpus
    - This is the file or other media with the training information for the NUL\bot
    - It will contain the intents and for each intent the utterances
    - It will also contain the language, name of the corpus, validation utterances and answers
        - Answers are for a Q&A corpus
    - The plural is Corpora

Channel
    - A channel is where a chatbot can be deployed
    - There are multiple places WhatsApp, Mobile, Web, API, Alexa, MS Teams and Facebook Messanger to name a few
    - There should be only one backend which connects to multiple channels

JS libraries
    - Brain.js
        - GPU accelerated Neural networks in JavaScript for Browsers and Node.js 
        - https://brain.js.org/#/
        - May not return exactly the same prediction
            - This is becasue the initialisation of the weights is not 0 but a random number
            - Each time a progam is ran there will be different values but should be within a range
    - Tensorflow.js
        - A library for machine learning in JavaScript 
        - https://www.tensorflow.org/js
        - npm install @tensorflow/tfjs-node (When installing on node!!)
    - These may be similar but Tensorflow is probably more complete
        - Also Tensorflow is asynchronous where as Brain.js is not
        - There may also be a need to rebuild bindings if environmental variables are changed
    - NLP.js
        - It has a Neural model which can be used similar to Brain.js

Regressions
    - Using both brain.js and Tensorflow.js for an Abelone example
    - This will be calculating the age of the Abelone from the rings

AI - Artificial Intelligence
    - Machine Learning and Deep Learning are part of AI
    - Deep Learning is a subset of Machine Learning

Classifiers
    - There are multiple classifiers, again a Brain.js and Tensorflow.js version will be done
    - Classification will include normalization and tokenisation
    - Text classification is the process of assigning tags or categories to text according to its content
        - It is a fundamental tasks of NLP and has broad applications
        - These include sentiment analysis, topic labeling, spam detection, and intent detection
    - Text classification can be done two different ways: manual or automatic classification
        - The latter is where NLP, AI and Machine Learning come in
    - There are many approaches to automatic NLP text classification, which fall into into three types of systems:
        - Rule-Based Systems
            - Rule-based approaches classify text into organized groups by using a set of handcrafted linguistic rules
            - These rules instruct the system to use semantically relevant elements of a text to identify relevant categories based on its content
            - Each rule consists of an antecedent or pattern and a predicted category
            - Rule-based systems are human comprehensible and can be improved over time
            - There are disadvantages to using this approach
                - There is specific in-depth domain knowledge needed
                - There is usually a lot of testing and analysis needed which makes this approach very time consuming
                - This approach is also difficult to maintain and may not scale well
        - Machine learning-based systems
            - Machine learning text classification learns to make classifications based on past observations
            - By using pre-labeled examples as training data, machine learning algorithms can learn the different associations between pieces of text
            - A “tag” is the pre-determined classification or category that any given text could fall into
            - The first step in training a machine learning NLP classifier is feature extraction which is a method to transform text into numerical values
                - This representation is in the form of a vector
                - One of the most frequently used approaches is bag of words, where a vector represents the frequency of a word in a predefined dictionary of words
            - There are multiple machine learning algorithms for creating text classification models
                - These include the Naive Bayes family of algorithms, support vector machines (SVM), and deep learning
        - Hybrid Systems
            - Hybrid systems combine a machine learning-trained base classifier with a rule-based system, used to further improve the results
            - These can be easily fine-tuned by adding specific rules for those conflicting tags that haven’t been correctly modeled by the base classifier
        - Metrics And Evaluation
            - Cross-validation is a common method to evaluate the performance of a text classifier
            - It works by splitting the training dataset into random, equal-length example sets
            - Then the classifiers make predictions on their respective sets, and the results are compared against the human-annotated tags
            - This will determine when a prediction was right (true positives and true negatives) and when it made a mistake (false positives, false negatives)
        - Why is Text Classification Important
            - Estimates reckon that approxiamtely 80% of all information is unstructured, with text being one of the most common types of unstructured data
            - The nature of text data is messy which makes analyzing, understanding, organizing, and sorting through it hard and time-consuming
            - This is where machine learning text classification comes in as using text classifiers, companies can automatically structure all manner of relevant text

!! Normalization
    - https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/normalize

!!! When writing in a foreign language there may be special character which even native speakers may forget to add
    - For example there are a couple of above vowel characters in French called accents, in Spanish too and others
    - These change both the sound and in some case meaning of words so is important to remember

!! Natural
    - This package is a general natural language facility for nodejs
        - https://github.com/NaturalNode/natural
    - npm install natural
    - There are several tokenisers available in this package

!! NLPJS    
    - Another package is NLPJS
    - An NLP library for building bots, with entity extraction, sentiment analysis, automatic language identify, and more
        - These are available in each language
    - https://github.com/axa-group/nlp.js#readme
    - To install the version for English (multiple languages available)
        - npm install @nlpjs/lang-en
    - NLPJS has a package for generating vectors from words
        - npm install @nlpjs/utils

MS Luis Classifier
    - Will need both an Azure account and a Luis account
        - https://www.luis.ai/
    - Azure has a 12 month free trial or pay as you go
    - Will need to install the nlpjs/nlu-luis package
        - npm install @nlpjs/nlu-luis

Perceptron (Building Your Own)
    - This will be the first part of building a custom classifier
    - https://en.wikipedia.org/wiki/Perceptron
    - The second part will be to build the Neural Network section
    
Classify Using NLPJS
    - Not the same as previous as NLPJS provided the Neural Network
        - The Neural Network is low level and NLPJS has several layers built on it
    - This will build the NLPJS suite which will use the NLP Basic package
        - npm install @nlpjs/basic

!!! - RASA
    - Rasa Open Source is a machine learning framework to automate text- and voice-based assistants
        - https://rasa.com/
        - https://rasa.com/docs/rasa/playground/

SIGDIAL 22
    - A paper about NLU Evaluation
    - Corpora for evaluating NLU services (like API.ai, RASA, Microsoft LUIS, ...) 
        - https://github.com/sebischair/NLU-Evaluation-Corpora
        - https://wwwmatthes.in.tum.de/pages/2lilqthsigbu/Vertical-Social-Software-VSS
    -

Stemming
    - Stemming is the process of producing morphological variants of a root/base word
        - Stemming programs are commonly referred to as stemming algorithms or stemmers
        - A stemming algorithm reduces the words “chocolates”, “chocolatey”, “choco” to the root word, “chocolate”
        - https://www.geeksforgeeks.org/introduction-to-stemming/
        - https://www.geeksforgeeks.org/nlp-how-tokenizing-text-sentence-words-works/
    - https://snowballstem.org/
    - A small string processing language for creating stemming algorithms for use in Information Retrieval, plus a collection of stemming algorithms implemented
    -
    